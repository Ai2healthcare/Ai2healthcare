---
layout: post
title: "Causal Tracing in Language Model"
author: Dr. Momiao Xiong, Houston, Texas, USA
date: 2023-05-18
categories: news
image: images/Momiao_Xiong.jpg
tags: AI, Deep Learning
---

- Title：MAIB-class-015:Causal Tracing in Language Model
- Date：10:00pm US East time, 05/20/2023
- Date：10:00am Beijing time, 05/21/2023
- Zoom  ID：933 1613 9423
- Zoom PWD：416262
- Zoom: [https://uwmadison.zoom.us/meeting/register/tJcudu-prTIuGNda1MsF8PKyRQlnGn06TP2E](https://uwmadison.zoom.us/meeting/register/tJcudu-prTIuGNda1MsF8PKyRQlnGn06TP2E)

<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/hKpz3rairr0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>

* Momiao Xiong, Ph. D, Professor in Department of Biostatistics snd Data Science , University of Texas, School of Public Health. Dr. Xiong graduated from the Department of Statistics at the University of Georgia in 1993. From 1993 to 1995, Dr. Xiong was postdoctoral fellow at the University of Southern California working with Michael Waterman.

* Research Interest： Causal Inference, Artificial Intelligence , Manifold Learning, Statistic Genetics and Bioinformatics .

Background

Causal Knowledge Graph in LM

Identify Causal Tokens for Prediction

Construct  Causal Information Flows in Transformer

Causal Tracing in Protein Language Modles

GAN for Causal Inference

Genetic Causation Studies

Causal Inference in AI

Causal Knowledge Graph in LM: This refers to the use of a knowledge graph within a language model to represent causal relationships between entities or concepts. It involves encoding causal information in the form of a graph to enable the model to understand and reason about cause-and-effect relationships.

Identify Causal Tokens for Prediction: In the context of natural language processing, this involves identifying specific tokens or words within a text that indicate causality. By identifying these causal tokens, models can better predict or understand causal relationships in the given context.

Construct Causal Information Flows in Transformer: This refers to modifying the Transformer architecture, a popular neural network model, to incorporate explicit causal information flows. By constraining the attention mechanism to only allow information flow from past to present, these models can better capture temporal dependencies and causality.

Causal Tracing in Protein Language Models: This involves analyzing and tracing causal relationships within language models specifically designed for understanding protein structures and interactions. By identifying causal links, these models can provide insights into how specific protein interactions lead to certain outcomes or functions.

GAN for Causal Inference: This involves using Generative Adversarial Networks (GANs) to perform causal inference tasks. GANs, which consist of a generator and discriminator, can be leveraged to learn causal relationships and generate samples that conform to a desired causal structure.

Genetic Causation Studies: These refer to studies conducted in genetics and genomics to investigate the causal relationships between genetic variations and phenotypic traits or diseases. These studies aim to identify genetic variants that have a causal effect on a particular trait or disease, often using methods such as genome-wide association studies (GWAS) or Mendelian randomization.

Causal Inference in AI: Causal inference in AI involves developing methods and algorithms to uncover causal relationships from observational or experimental data. It aims to understand cause-and-effect relationships rather than mere correlations, enabling AI systems to make more informed decisions and interventions. Causal inference techniques can be applied in various domains, including healthcare, economics, and social sciences, to gain insights and make causal claims from data.

经过大数据训练后的语言模型包含了极大的信息。这些信息都隐藏在有向图的变换器中，隐含在embedding中。利用已经训练好的语言模型追踪因果信息在语言推理中的运动，构建大型描述外部世界的因果网络，利用蛋白质语言模型和DNA语言模型开辟一条实现全基因组和多组合数据因果分析对于生物的基础研究，疾病的诊冶和药物的开发具有十分重要的理论和实际意义。

在语言模型中的因果知识图：这指的是在语言模型中使用知识图来表示实体或概念之间的因果关系。它通过将因果信息编码成图形的形式，使模型能够理解和推理出因果关系。

识别预测中的因果标记：在自然语言处理的背景下，这涉及识别文本中特定的标记或词语，这些标记指示因果关系。通过识别这些因果标记，模型能够更好地预测或理解给定语境中的因果关系。

在Transformer中构建因果信息流：这指的是修改Transformer架构（一种常用的神经网络模型），以包含显式的因果信息流。通过限制注意机制只允许从过去到现在的信息流，这些模型能够更好地捕捉时间依赖性和因果关系。

蛋白质语言模型中的因果追踪：这涉及分析和追踪专门设计用于理解蛋白质结构和相互作用的语言模型中的因果关系。通过识别因果联系，这些模型可以揭示特定蛋白质相互作用如何导致特定结果或功能。

用于因果推断的GAN：这涉及使用生成对抗网络（GAN）进行因果推断任务。GAN由生成器和判别器组成，可以用于学习因果关系并生成符合所需因果结构的样本。

遗传因果研究：这些研究是在遗传学和基因组学领域进行的，旨在调查基因变异与表型特征或疾病之间的因果关系。这些研究旨在确定对特定特征或疾病具有因果效应的基因变异，通常使用基因组关联研究（GWAS）或Mendelian随机化等方法。

人工智能中的因果推断：人工智能中的因果推断涉及开发从观察数据或实验数据中揭示因果关系的方法和算法。它旨在理解因果关系而不仅仅是相关性，使人工智能系统能够做出更明智的决策和干预。因果推断技术可以应用于医疗保健、经济学和社会科学等各个领域，以从数据中获得洞察力和提出因果假设。

      


• 

