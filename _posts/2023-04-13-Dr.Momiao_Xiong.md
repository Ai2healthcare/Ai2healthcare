---
layout: post
title: "Vision Transformer and its Applications"
author: Dr. Momiao Xiong, Houston, Texas, USA
date: 2023-04-13
categories: news
image: images/Momiao_Xiong.jpg
tags: AI, Deep Learning;Vision;Transformer
---

- Title：MAIB-class-012:Vision Transformer and its Applications
- Date：10:00pm US East time, 04/015/2023
- Date：10:00am Beijing time, 04/16/2023
- Zoom  ID：933 1613 9423
- Zoom PWD：416262
- Zoom: [https://uwmadison.zoom.us/meeting/register/tJcudu-prTIuGNda1MsF8PKyRQlnGn06TP2E](https://uwmadison.zoom.us/meeting/register/tJcudu-prTIuGNda1MsF8PKyRQlnGn06TP2E)

<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/hKpz3rairr0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>

* Momiao Xiong, Ph. D, Professor in Department of Biostatistics snd Data Science , University of Texas, School of Public Health. Dr. Xiong graduated from the Department of Statistics at the University of Georgia in 1993. From 1993 to 1995, Dr. Xiong was postdoctoral fellow at the University of Southern California working with Michael Waterman.

* Research Interest： Causal Inference, Artificial Intelligence , Manifold Learning, Statistic Genetics and Bioinformatics .

* [https://theaisummer.com/diffusion-models/#:~:text=Diffusion%20models%20are%20a%20new,to%20train%20large%2Dscale%20models](https://theaisummer.com/diffusion-models/#:~:text=Diffusion%20models%20are%20a%20new,to%20train%20large%2Dscale%20models)

* [https://towardsdatascience.com/understanding-graph-convolutional-networks-for-node-classification-a2bfdb7aba7b](https://towardsdatascience.com/understanding-graph-convolutional-networks-for-node-classification-a2bfdb7aba7b)

* [https://medium.com/red-buffer/implementation-and-understanding-of-graph-neural-networks-gnn-54084c8a0e24](https://medium.com/red-buffer/implementation-and-understanding-of-graph-neural-networks-gnn-54084c8a0e24)

Background

变换器是人工智能在近五年内的最为重要的突破，它在自然语言处理中起了核心的作用。变换器由编码，解码两部分组成。它与自编码器的主要不同之处有以下几点。（1）变换器的编码和解码都是一类特殊的神经网络。它们是由多头，多层次的Self Attention网络组成。编码和解码器的输出都包括了序列数据之间最复杂和最本质的相互作用关系。由他们的输出（即embedding)所形成的空间比变分自编码器隐式高斯空间更为广泛，表达力更强，因而予报精度更高。（2）变换器更容易用作生成器，可生成代码，数学公式，甚至用于推理，计划和决策等。(3)易于推广到图象，视频等数据分析。

变换器在最近这几年也从自然语言处理推广到图象，音频和视频的数据分析中。因为标准的变换器，其计算复杂性是二次。图象，音频和视频都是高维数据，标准的变换器在这些数据中的应用需要巨大的计算量，因此只有改进，才能适应在图象，视频等数据分析的需要。这就导致许多不同形式的变换器。我们就要分几次介绍变换器。介绍它们在分类，描述图象，视频，图象切割，检查产品的质量，诊断疾病，寻找癌组织的位置中的应用。.


讲座延伸：

变换器是一种非常强大的神经网络结构，在自然语言处理领域有着广泛的应用。近年来，它也被广泛应用于图像、音频和视频等领域。但是，由于标准变换器的计算复杂度是二次的，因此在处理高维数据时需要改进。
以下是变换器在不同领域中的一些应用：

1.	分类

变换器可以用于分类任务，如图像分类、音频分类和文本分类等。在图像分类任务中，变换器可以将图像中的每个像素都视为序列数据，然后将其编码成嵌入向量。这些嵌入向量可以用于训练一个分类模型，用于对新的图像进行分类。

2.	描述图像

变换器还可以用于描述图像，这是一种生成任务。在这种情况下，变换器的解码器可以被视为一个生成器，它可以生成一些嵌入向量，这些向量可以转化为图像。这种方法可以用于生成一些特定领域的图像，如医学图像、艺术图像等。

3.	视频

变换器也可以用于处理视频数据。在这种情况下，每个视频帧都可以被视为一个图像，然后将其传递给变换器进行处理。这种方法可以用于视频分类、视频描述等任务。

4.	图像切割

变换器还可以用于图像分割任务。在这种情况下，变换器的编码器可以将图像中的每个像素都视为序列数据，然后将其编码成嵌入向量。这些嵌入向量可以用于训练一个分割模型，用于对新的图像进行分割。

5.	产品质量检查

变换器还可以用于产品质量检查。在这种情况下，变换器可以将产品图像中的每个像素都视为序列数据，然后将其编码成嵌入向量。这些嵌入向量可以用于训练一个分类模型，用于检测产品的质量。

6.	疾病诊断

变换器还可以用于医学图像中的疾病诊断。在这种情况下，变换器可以将医学图像中的每个像素都视为序列数据，然后将其编码成嵌入向量。这些嵌入向量可以用于训练一个分类模型，用于检测患者是否患有某种疾病。

7.	癌组织定位

变换器还可以用于定位医学图像中的癌组织。在这种情况下，变换器可以将

