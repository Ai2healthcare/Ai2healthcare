---
layout: post
title: "Toward Personal Language Models"
date: 2023-01-24
categories: news
image: ![](images/Yi_Wang_Fudan.jpg){width=50% height=300px}
tags: 

---
- Speaker: Dr. Yi Wang, Fudan University
- Title： MAIB讲座第6期: Toward Personal Language Models
- Date：9:00pm US East time, 01/28/2023
- Date：10:00am Beijing time, 01/29/2023
- Zoom  ID： 933 1613 9423
- Zoom PWD： 416262
- Key words: Toward，Personal，Language，Models

Title: Toward Personal Language Models

Abstract:

Language models provide the joint probability distribution of a symbolic sequence. A language model can generate novel sequences which enables article writing and dialogues. It can also predict the likelihood of given sequences which enables blank filling, choices on multiple answers or judgement of propositions. Thus, language models are keys to future artificial general intelligence (AGI). Currently huge language models dominate the field. They cost huge computation, emit tons of CO2, require expensive GPU server to deploy and block small labs and individual researchers. In this study, I explored various technologies to a personal language model which is small, elegant, cheap, fast and affordable to everyone. These technologies include: (1) A simple bare CUDA/C++ implementation of every operator from the scratch. (2) Several novel candidate architectures. (3) A novel entropy-based sampling method for text generation, aka Top-E sampling. (4) Elegant designs, such as byte level modeling, extreme deep and narrow design, single head batch computation etc. (5) Quantization with VNNI instructions. I open sourced the June version with two pretrained models: PubMed English model and WuDao Chinese models. A more recent Traditional Chinese Medicine model is also available on WeChat based on a state-of-the-art model with only 3 million parameters.

语言模型提供符号序列的联合概率分布。 语言模型可以生成新颖的序列，从而实现文章写作和对话。 它还可以预测给定序列的可能性，从而能够填空、选择多个答案或判断命题。 因此，语言模型是未来通用人工智能 (AGI) 的关键。 目前，庞大的语言模型在该领域占据主导地位。 它们需要巨大的计算成本，排放大量的二氧化碳，需要昂贵的 GPU 服务器来部署和阻止小型实验室和个人研究人员。 在这项研究中，我探索了各种技术，以形成一种小巧、优雅、廉价、快速且人人都能负担得起的个人语言模型。 这些技术包括：(1) 从头开始对每个运算符进行简单的裸 CUDA/C++ 实现。 (2) 几种新颖的候选架构。 (3) 一种新的基于熵的文本生成抽样方法，又名 Top-E 抽样。 (4) 优雅的设计，如字节级建模、极深极窄设计、单头批计算等。 (5) VNNI 指令量化。 我开源了 6 月版本的两个预训练模型：PubMed 英文模型和五道中文模型。 基于只有 300 万个参数的最先进模型，微信上也提供了更新的中医模型。

Bio:

Dr. Yi Wang is a Youth Research Associate in School of Life Science in Fudan University. He obtained Bachelor and PhD in the same institution. In his PostDoc journey in Human Genome Sequencing Center in Baylor College of Medicine, he joined the 1000 genome project and his SNPTools package obtained consensus from the community and produces PHASE I imputation result of the project. His XiaoBu AI doctor was well accepted and was deployed in the Children’s Hospital of Fudan University. 

王一博士，复旦大学生命科学学院青年研究员。 他在同一所大学获得学士和博士学位。 在贝勒医学院人类基因组测序中心的博士后之旅中，他加入了 1000 基因组计划，他的 SNPTools 包获得了社区的共识，并产生了该项目的 PHASE I imputation 结果。 他的小布AI医生很受欢迎，被部署在复旦大学附属儿童医院。


<p align="center">
<iframe width="560" height="315" src="https://www.youtube.com/embed/ocUonfIUWPw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>

